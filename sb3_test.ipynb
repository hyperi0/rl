{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 12:43:34.565363: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-27 12:43:35.426336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_freq = 1000\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=save_freq,\n",
    "  save_path=\"./logs/\",\n",
    "  name_prefix=\"rl_model\",\n",
    "  save_replay_buffer=False,\n",
    "  save_vecnormalize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/ben/.pyenv/versions/3.11.3/envs/rl/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/ben/.pyenv/versions/3.11.3/envs/rl/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35       |\n",
      "|    ep_rew_mean        | 35       |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.624   |\n",
      "|    explained_variance | -0.0466  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 1.44     |\n",
      "|    value_loss         | 9.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 42.1     |\n",
      "|    ep_rew_mean        | 42.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 379      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.617   |\n",
      "|    explained_variance | 0.0653   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 2.31     |\n",
      "|    value_loss         | 7.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 41.4     |\n",
      "|    ep_rew_mean        | 41.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 392      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.666   |\n",
      "|    explained_variance | -0.0356  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -1.46    |\n",
      "|    value_loss         | 97.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 39.5     |\n",
      "|    ep_rew_mean        | 39.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 400      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.686   |\n",
      "|    explained_variance | -0.00542 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 1.37     |\n",
      "|    value_loss         | 5.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 40.5     |\n",
      "|    ep_rew_mean        | 40.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 406      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.67    |\n",
      "|    explained_variance | 0.0126   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.16     |\n",
      "|    value_loss         | 5.17     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 43.8      |\n",
      "|    ep_rew_mean        | 43.8      |\n",
      "| time/                 |           |\n",
      "|    fps                | 407       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.661    |\n",
      "|    explained_variance | -0.000344 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 1.05      |\n",
      "|    value_loss         | 4.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 44.6     |\n",
      "|    ep_rew_mean        | 44.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.666   |\n",
      "|    explained_variance | 5.62e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.11     |\n",
      "|    value_loss         | 4.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 46.4     |\n",
      "|    ep_rew_mean        | 46.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 415      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.633   |\n",
      "|    explained_variance | 0.000319 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    value_loss         | 3.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 47.3     |\n",
      "|    ep_rew_mean        | 47.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 419      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.655   |\n",
      "|    explained_variance | 0.000311 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    value_loss         | 3.16     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 49.3      |\n",
      "|    ep_rew_mean        | 49.3      |\n",
      "| time/                 |           |\n",
      "|    fps                | 424       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.662    |\n",
      "|    explained_variance | -3.19e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 0.898     |\n",
      "|    value_loss         | 2.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 53       |\n",
      "|    ep_rew_mean        | 53       |\n",
      "| time/                 |          |\n",
      "|    fps                | 424      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.526   |\n",
      "|    explained_variance | 6e-05    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 1.08     |\n",
      "|    value_loss         | 2.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 55.8     |\n",
      "|    ep_rew_mean        | 55.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 420      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.618   |\n",
      "|    explained_variance | 0.000436 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.733    |\n",
      "|    value_loss         | 1.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 58       |\n",
      "|    ep_rew_mean        | 58       |\n",
      "| time/                 |          |\n",
      "|    fps                | 422      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.556   |\n",
      "|    explained_variance | 4.88e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.742    |\n",
      "|    value_loss         | 1.57     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 61.5      |\n",
      "|    ep_rew_mean        | 61.5      |\n",
      "| time/                 |           |\n",
      "|    fps                | 423       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.51     |\n",
      "|    explained_variance | -2.75e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 0.361     |\n",
      "|    value_loss         | 1.25      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 63.7     |\n",
      "|    ep_rew_mean        | 63.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 426      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0.000439 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.576    |\n",
      "|    value_loss         | 0.956    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 67.4     |\n",
      "|    ep_rew_mean        | 67.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 428      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.491   |\n",
      "|    explained_variance | 0.000165 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.257    |\n",
      "|    value_loss         | 0.702    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 71.2     |\n",
      "|    ep_rew_mean        | 71.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 430      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.435   |\n",
      "|    explained_variance | 9.55e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.263    |\n",
      "|    value_loss         | 0.484    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 77        |\n",
      "|    ep_rew_mean        | 77        |\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.466    |\n",
      "|    explained_variance | -1.92e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 0.248     |\n",
      "|    value_loss         | 0.308     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 80.6      |\n",
      "|    ep_rew_mean        | 80.6      |\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.456    |\n",
      "|    explained_variance | -1.22e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 0.129     |\n",
      "|    value_loss         | 0.175     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 84        |\n",
      "|    ep_rew_mean        | 84        |\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.436    |\n",
      "|    explained_variance | -3.67e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 0.137     |\n",
      "|    value_loss         | 0.0778    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for filename in os.listdir(\"./logs\"):\n",
    "    os.remove(\"./logs/\" + filename)\n",
    "\n",
    "total_steps = 10000\n",
    "\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=total_steps,\n",
    "            callback=checkpoint_callback,\n",
    "            progress_bar=True)\n",
    "\n",
    "model.save(\"./logs/a2c_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filenames = [\"./logs/rl_model_\" + str(i*save_freq) + \"_steps.zip\"\n",
    "             for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./logs/rl_model_1000_steps.zip\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "./logs/rl_model_1000_steps.zip\n",
      "    Total reward: [91.]\n",
      "./logs/rl_model_2000_steps.zip\n",
      "./logs/rl_model_2000_steps.zip\n",
      "    Total reward: [89.]\n",
      "./logs/rl_model_3000_steps.zip\n",
      "./logs/rl_model_3000_steps.zip\n",
      "    Total reward: [126.]\n",
      "./logs/rl_model_4000_steps.zip\n",
      "./logs/rl_model_4000_steps.zip\n",
      "    Total reward: [128.]\n",
      "./logs/rl_model_5000_steps.zip\n",
      "./logs/rl_model_5000_steps.zip\n",
      "    Total reward: [223.]\n",
      "./logs/rl_model_6000_steps.zip\n",
      "./logs/rl_model_6000_steps.zip\n",
      "    Total reward: [260.]\n",
      "./logs/rl_model_7000_steps.zip\n",
      "./logs/rl_model_7000_steps.zip\n",
      "    Total reward: [235.]\n",
      "./logs/rl_model_8000_steps.zip\n",
      "./logs/rl_model_8000_steps.zip\n",
      "    Total reward: [181.]\n",
      "./logs/rl_model_9000_steps.zip\n",
      "./logs/rl_model_9000_steps.zip\n",
      "    Total reward: [366.]\n",
      "./logs/rl_model_10000_steps.zip\n",
      "./logs/rl_model_10000_steps.zip\n",
      "    Total reward: [180.]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    m = A2C.load(filename, env=env)\n",
    "    env = m.get_env()\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _state = m.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        env.render(\"human\")\n",
    "    print(filename)\n",
    "    print(\"    Total reward: \" + str(total_reward))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total reward: [164.]\n"
     ]
    }
   ],
   "source": [
    "model = A2C.load(\"./logs/a2c_trained.zip\", env=env)\n",
    "env = model.get_env()\n",
    "obs = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    env.render(\"human\")\n",
    "print(\"    Total reward: \" + str(total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
